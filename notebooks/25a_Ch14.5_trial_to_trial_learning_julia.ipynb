{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fba84bc",
   "metadata": {},
   "source": [
    "# Chapter 14.5: Trial-to-trial learning in Dutch (Simulation in Julia)\n",
    "\n",
    "Importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4de421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using JudiLing, JudiLingMeasures, CSV, DataFrames, ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c6731a",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "First, if you haven't done so before, download the trial-level data from the Dutch Lexicon Project (Keuleers et al, 2010) from [here](https://osf.io/uw7t6/) and store it as `dlp-trials.txt` in the `dat` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7686d2",
   "metadata": {},
   "source": [
    "Now we load the file into Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ae3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp = JudiLing.load_dataset(\"../dat/dlp-trials.txt\", delim=\"\\t\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0823a",
   "metadata": {},
   "source": [
    "We subset the file to only include responses of the first participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdff1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp_part1 = dlp[dlp.participant .== 1,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first(dlp_part1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66908fcc",
   "metadata": {},
   "source": [
    "Divide the data into words and nonwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780657c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp_words = dlp_part1[dlp_part1.lexicality .== \"W\",:]\n",
    "dlp_nonwords = dlp_part1[dlp_part1.lexicality .== \"N\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6267a",
   "metadata": {},
   "source": [
    "Sort each by the order they were presented to the participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560fd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp_words = sort(dlp_words, [:order])\n",
    "dlp_nonwords = sort(dlp_nonwords, [:order])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4b002",
   "metadata": {},
   "source": [
    "## Initialising the model\n",
    "\n",
    "Load an S matrix using fasttext vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48982f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp_words_small, S = JudiLing.load_S_matrix_from_fasttext(dlp_words, :nl, target_col=:spelling);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88fbb4",
   "metadata": {},
   "source": [
    "Create cue objects for the words and nonwords respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f74f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_obj_words, cue_obj_nonwords = JudiLing.make_combined_cue_matrix(dlp_words_small, dlp_nonwords,\n",
    "                                                            grams=3, target_col=:spelling);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e186b9",
   "metadata": {},
   "source": [
    "Calculate F and G mappings for the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8379068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F = JudiLing.make_transform_matrix(cue_obj_words.C, S)\n",
    "G = JudiLing.make_transform_matrix(S, cue_obj_words.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0ad9e",
   "metadata": {},
   "source": [
    "Now, we create the target semantic vectors for the nonwords. For this, we first project the nonword form vectors into semantic space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8ed4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S_nonwords = cue_obj_nonwords.C * F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659114",
   "metadata": {},
   "source": [
    "Next, we add the semantic vectors of \"niet\" and \"woord\" to the predicted vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "niet_vec = S[dlp_words_small.spelling .== \"niet\",:]\n",
    "woord_vec = S[dlp_words_small.spelling .== \"woord\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:size(S_nonwords, 1)\n",
    "    S_nonwords[i, :] = S_nonwords[i, :] + vec(niet_vec) + vec(woord_vec)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce36016",
   "metadata": {},
   "source": [
    "## Simulating the experiment\n",
    "\n",
    "First, we need to create a dataframe with all words and nonwords, as well as an S matrix with the target vectors for both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66251dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlp_part1_final = vcat(dlp_words_small, dlp_nonwords)\n",
    "S_part1 = vcat(S, S_nonwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07256473",
   "metadata": {},
   "source": [
    "We sort both by the order they were presented to the participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e51a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S_part1_ordered = S_part1[sortperm(dlp_part1_final.order), :]\n",
    "dlp_part1_ordered = sort(dlp_part1_final, [:order])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46034c",
   "metadata": {},
   "source": [
    "Now create a cue object for the combined dataset. Provide `cue_obj_words` to the function, so that the `i2f` and `f2i` matrices are reused for creating the new C matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2ce50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cue_obj = JudiLing.make_cue_matrix(dlp_part1_ordered, cue_obj_words, grams=3, target_col=:spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc281c5",
   "metadata": {},
   "source": [
    "Now we \"run\" the static simulation. Since F and G do not change throughout the course of the experiment, we can simply map the C and Shat matrices using F and G in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ba5c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Shat_collection_static = cue_obj.C * F\n",
    "Chat_collection_static = Shat_collection_static * G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cdc36",
   "metadata": {},
   "source": [
    "Extract measures from the static simulation. For simplicity, we restrict ourselves to words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afc850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measures_static = deepcopy(dlp_words_small)\n",
    "acc_comp, cor_s = JudiLing.eval_SC(Shat_collection_static[dlp_part1_ordered.lexicality .== \"W\",:], S, R=true)\n",
    "measures_static[!,\"SemanticDensity\"] = JudiLingMeasures.density(cor_s, n=8)\n",
    "measures_static[!,\"L1Chat\"] = JudiLingMeasures.L1Norm(Chat_collection_static[dlp_part1_ordered.lexicality .== \"W\",:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c463d7d",
   "metadata": {},
   "source": [
    "For the dynamic simulation, we loop over all trials, first compute the $\\hat{s}$ and $\\hat{c}$ vectors for the trial and save them. Then the mappings F and G are updated to decrease the error between the form and meaning of the currently presented stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shat_collection_dynamic = zeros(size(S_part1_ordered))\n",
    "Chat_collection_dynamic = zeros(size(cue_obj.C))\n",
    "\n",
    "@showprogress for trial in 1:size(dlp_part1_ordered, 1)\n",
    "    shat = cue_obj.C[trial:trial, :] * F\n",
    "    chat = shat * G\n",
    "    Shat_collection_dynamic[trial:trial,:] = shat\n",
    "    Chat_collection_dynamic[trial:trial,:] = chat\n",
    "    \n",
    "    F = JudiLing.wh_learn(cue_obj.C[trial:trial, :], S_part1_ordered[trial:trial, :], eta=0.001, weights = F,\n",
    "                          n_epochs=1)\n",
    "    G = JudiLing.wh_learn(S_part1_ordered[trial:trial, :], cue_obj.C[trial:trial, :], eta=0.001, weights = G,\n",
    "                          n_epochs=1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ddf53",
   "metadata": {},
   "source": [
    "Extract dynamic measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfc94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measures_dynamic = deepcopy(dlp_words_small)\n",
    "acc_comp, cor_s = JudiLing.eval_SC(Shat_collection_dynamic[dlp_part1_ordered.lexicality .== \"W\",:], S, R=true)\n",
    "measures_dynamic[!,\"SemanticDensity\"] = JudiLingMeasures.density(cor_s, n=8)\n",
    "measures_dynamic[!,\"L1Chat\"] = JudiLingMeasures.L1Norm(Chat_collection_dynamic[dlp_part1_ordered.lexicality .== \"W\",:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1531a6",
   "metadata": {},
   "source": [
    "Save measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../res/dlp-trial-measures-static.csv\", measures_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../res/dlp-trial-measures-dynamic.csv\", measures_dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040c164-5489-47ad-93f0-49dd6e8aa1eb",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Keuleers, E., Diependaele, K., and Brysbaert, M. (2010). Practice effects in large-scale visual word recognition studies: A lexical decision study on 14,000 dutch mono-and disyllabic words and nonwords. Frontiers in psychology, 1:174."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
