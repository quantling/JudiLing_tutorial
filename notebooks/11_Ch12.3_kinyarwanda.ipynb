{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd0c79d",
   "metadata": {},
   "source": [
    "# Chapter 12.3: Kinyarwanda verbs\n",
    "\n",
    "Load the usual packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b886cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, JudiLing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b574e",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "First, download the file \"kinyarwandaVerbsExtensionsSylJuliaTestCombo.csv\" from the Supplementary Materials of van de Vijver, Uwambayinema and Chuang (2024) which can be found [here](https://osf.io/jdaqb/) and store it in \"dat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb62cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"https://osf.io/8uzah/download\", \"../dat/kinyarwanda_verbs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877357a4",
   "metadata": {},
   "source": [
    "Next, we load the full dataset for inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90886b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = JudiLing.load_dataset(\"../dat/kinyarwanda_verbs.csv\", delim=\";\");\n",
    "first(dat[:, 1:6],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245f510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first(dat[:,7:11], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3623a",
   "metadata": {},
   "source": [
    "Since the `loading_data_careful_split` can only deal with comma-separated files, we first need to save our dataset as a proper .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46834c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "CSV.write(\"../dat/kinyarwanda_verbs.csv\", dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd657c",
   "metadata": {},
   "source": [
    "Now we can reload the data, splitting into training and validation data. We use the `loading_data_careful_split` function, ensuring that all cues, lexemes and inflectional features in the validation data have already been seen in the training data.\n",
    "Following van de Vivjer et al. (2024) we use bi-syllables, and hold out 10% of the data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = JudiLing.loading_data_careful_split(\n",
    "                        \"../dat/kinyarwanda_verbs.csv\", \n",
    "                        \"kinyarwanda\", \n",
    "                        \"../dat/careful\",\n",
    "                        [\"Lexeme\", \"Person\", \"Number\", \"Tense\", \"Voice\", \"Mood\", \"Extension\", \"Aspect\"],\n",
    "                        n_grams_target_col = \"WordSyl2\",\n",
    "                        n_grams_tokenized = true,\n",
    "                        n_grams_sep_token = \".\",\n",
    "                        n_grams_keep_sep = true,\n",
    "                        grams = 2,\n",
    "                        val_ratio = 0.1,\n",
    "                        random_seed = 42,\n",
    "                        verbose=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369c5c9",
   "metadata": {},
   "source": [
    "Inspect the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad458a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first(data_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a398c34",
   "metadata": {},
   "source": [
    "Inspect the respective sizes of training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8049b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eef513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988aec8",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Matrix preparation\n",
    "\n",
    "We now create cue objects for both the training and validation data. For this, we use the `make_combined_cue_matrix` function which ensures that there are columns for all cues in both the training and validation data in the training cue matrix. We also tell the function that we use the form representation in column `:WordSyl2`, which are already tokenized, and tokens are separated by a `\".\"`. We want to use bi-syllables, so set `grams=2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4e18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cue_obj_train, cue_obj_val = JudiLing.make_combined_cue_matrix(data_train, \n",
    "                                                               data_val,\n",
    "                                                               grams=2, \n",
    "                                                               tokenized=true,\n",
    "                                                               sep_token=\".\", \n",
    "                                                               keep_sep=true, \n",
    "                                                               target_col=:WordSyl2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "JudiLing.display_matrix(data_train, :WordSyl2, cue_obj_train, cue_obj_train.C, :C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45aaf3c",
   "metadata": {},
   "source": [
    "Now create semantic matrices for both datasets using `make_combined_S_matrix`. We want `:Lexeme` as the base for all semantic vectors, and all inflectional features (`[\"Person\", \"Number\", \"Tense\", \"Voice\", \"Mood\", \"Extension\", \"Aspect\"]`) as feature vectors. We also set the dimension of the semantic matrix to be the same as that of the cue matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_val = JudiLing.make_combined_S_matrix(data_train, \n",
    "                                                data_val, \n",
    "                                                [\"Lexeme\"], \n",
    "                                                [\"Person\", \"Number\", \"Tense\", \"Voice\", \"Mood\", \"Extension\", \"Aspect\"], \n",
    "                                                ncol=size(cue_obj_train.C, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccc000",
   "metadata": {},
   "source": [
    "### Training (Seen) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d26018",
   "metadata": {},
   "source": [
    "Next, we train the F matrix on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b958188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F = JudiLing.make_transform_matrix(cue_obj_train.C, S_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc253304",
   "metadata": {},
   "source": [
    "... and compute the predicted semantic matrix for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd324ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shat_train = cue_obj_train.C * F;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b9fa0",
   "metadata": {},
   "source": [
    "Evaluate comprehension accuracy on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "JudiLing.eval_SC(Shat_train, S_train, data_train, :WordSyl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d624454",
   "metadata": {},
   "source": [
    "Moving on to production, we first train the G matrix and predicted form vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8988d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = JudiLing.make_transform_matrix(S_train, cue_obj_train.C);\n",
    "Chat_train = S_train * G;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eda31d",
   "metadata": {},
   "source": [
    "Next, we need to assemble the produced forms from the predicted form vector. For this we make use of the `learn_paths` algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d627380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_learn_train = JudiLing.learn_paths(data_train,\n",
    "                                        cue_obj_train,\n",
    "                                        S_train,\n",
    "                                        F,\n",
    "                                        Chat_train,\n",
    "                                        threshold=0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9fd55",
   "metadata": {},
   "source": [
    "...and evaluate the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c52649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JudiLing.eval_acc(res_learn_train, cue_obj_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb7dbd",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "## Exercise 1\n",
    "Evaluating the model on the validation data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125be424",
   "metadata": {},
   "source": [
    "First compute the predicted semantic vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f6f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Shat_val = cue_obj_val.C * F;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7cc0e",
   "metadata": {},
   "source": [
    "...and evaluate comprehension accuracy on the unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86acab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JudiLing.eval_SC(Shat_val, S_val, S_train, data_val, data_train, :WordSyl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d244000",
   "metadata": {},
   "source": [
    "Moving on to production, compute the predicted form matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232fd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chat_val = S_val * G;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a390b5",
   "metadata": {},
   "source": [
    "Now we need to again run the `learn_paths` algorithm for the validation data. We need to use the somewhat more complex version of the algorithm. First we need to compute the maximum number of cues which can occur in a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de106ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = JudiLing.cal_max_timestep(data_train, data_val, :WordSyl2, tokenized=true, sep_token=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad5214",
   "metadata": {},
   "source": [
    "Now we can proceed to run the algorithm. Note that we decrease the `threshold` slightly to 0.005:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ec84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_learn_val = JudiLing.learn_paths(data_train,\n",
    "                                    data_val,\n",
    "                                    cue_obj_train.C,\n",
    "                                    S_val,\n",
    "                                    F,\n",
    "                                    Chat_val,\n",
    "                                    cue_obj_train.A,\n",
    "                                    cue_obj_train.i2f,\n",
    "                                    cue_obj_train.f2i,\n",
    "                                    Shat_val = Shat_val,\n",
    "                                    max_t = max_t,\n",
    "                                    grams=2,\n",
    "                                    target_col=:WordSyl2,\n",
    "                                    tokenized=true,\n",
    "                                    sep_token=\".\",\n",
    "                                    keep_sep=true,\n",
    "                                    verbose=true,\n",
    "                                    threshold=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JudiLing.eval_acc(res_learn_val, cue_obj_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe194c",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97134ff",
   "metadata": {},
   "source": [
    "Call the `accuracy_comprehension` function on the validation data, supplying all features as base and inflections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fcb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_comp = JudiLing.accuracy_comprehension(S_val, S_train, Shat_val, \n",
    "                                            data_val, data_train, target_col=\"WordSyl2\",\n",
    "                                            base=[\"Lexeme\"], \n",
    "                                            inflections=[\"Person\", \"Number\", \"Tense\", \n",
    "                                                         \"Voice\", \"Mood\", \"Extension\", \n",
    "                                                         \"Aspect\"])\n",
    "acc_comp_dfr = acc_comp.dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055dd8f",
   "metadata": {},
   "source": [
    "Keep only the rows with errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30437d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = acc_comp_dfr[acc_comp_dfr.correct .== 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7557447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82154a",
   "metadata": {},
   "source": [
    "Now we need to count how many times there were errors for each of the features. We can do this manually or by summing each of the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum.(eachcol(errors[:,\n",
    "        [:Lexeme, :Person, :Number, :Tense, :Voice, :Mood, :Extension, :Aspect]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cea1c",
   "metadata": {},
   "source": [
    "The numbers tell us how many times the pertinent feature was understood correctly. Evidently, the second to last feature (Extension) was not understood the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(acc_comp_dfr[acc_comp_dfr.correct .== 0,:], :Extension), nrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa346a2",
   "metadata": {},
   "source": [
    "The reason for this is quite straightforward: within the inflection features, the Extension features has the most unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697ac7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine(groupby(data_val, :Extension), nrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d212616",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "van de Vijver, R., Uwambayinema, E. & Chuang, Y. (2024). Comprehension and production of Kinyarwanda verbs in the Discriminative Lexicon. Linguistics, 62(1), 79-119. https://doi.org/10.1515/ling-2021-0164"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
