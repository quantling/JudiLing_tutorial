{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12.11: Multilingual learning\n",
    "\n",
    "Load libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JudiLing, DataFrames, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_multi = JudiLing.load_dataset(\"../dat/dat_multi.csv\", delim=\"\\t\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, words = JudiLing.load_S_matrix(\"../dat/S_multi.csv\", header=true, sep=\",\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monolingual learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_en = dat_multi[dat_multi.Language .== \"ENG\",:];\n",
    "dat_de = dat_multi[dat_multi.Language .== \"GER\",:];\n",
    "dat_zh = dat_multi[dat_multi.Language .== \"MAN\",:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_obj_en = JudiLing.make_cue_matrix(dat_en, grams=3, target_col=:Phon);\n",
    "cue_obj_de = JudiLing.make_cue_matrix(dat_de, grams=3, target_col=:Phon);\n",
    "cue_obj_zh = JudiLing.make_cue_matrix(dat_zh, grams=3, target_col=:Phon);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_en = S[1:190,:];\n",
    "S_de = S[191:380,:];\n",
    "S_zh = S[381:570,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(dat_en, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_seq = JudiLing.make_learn_seq(dat_en.simFreq, random_seed=314);\n",
    "eval_size = 2747\n",
    "n_evals = Int64(length(learn_seq)/eval_size); # 6\n",
    "F = zeros(size(cue_obj_en.C)[2], size(S)[2]);\n",
    "\n",
    "accs_comp = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_en.C, S_en, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    Shat = cue_obj_en.C * F\n",
    "    acc = JudiLing.eval_SC(Shat, S)\n",
    "    push!(accs_comp, acc)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making all the previous steps into a function\n",
    "function monolingual_learning_comp(data, cue_obj, S, eval_size, whole_epoch_rep)\n",
    "    learn_seq = repeat(JudiLing.make_learn_seq(data.simFreq, random_seed=314), whole_epoch_rep);\n",
    "    evals = collect(Int64, 1:(length(learn_seq)/eval_size))\n",
    "    F = zeros(size(cue_obj.C)[2], size(S)[2])\n",
    "\n",
    "    accs = []\n",
    "    for i in evals\n",
    "        learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "        F = JudiLing.wh_learn(cue_obj.C, S, learn_seq=learn_seq_epoch, eta=0.01, weights=F, n_epochs=1)\n",
    "        Shat = cue_obj.C * F\n",
    "        acc = JudiLing.eval_SC(Shat, S)\n",
    "        push!(accs, acc)\n",
    "    end\n",
    "    accs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_en = monolingual_learning_comp(dat_en, cue_obj_en, S_en, 2747, 1);\n",
    "accs_de = monolingual_learning_comp(dat_de, cue_obj_de, S_de, 2747, 1);\n",
    "accs_zh = monolingual_learning_comp(dat_zh, cue_obj_zh, S_zh, 2747, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_en, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(accs_de, label=\"German\")\n",
    "plot!(accs_zh, label=\"Mandarin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double the learning: changing \"whole_epoch_rep\" from 1 to 2 \n",
    "accs_en = monolingual_learning_comp(dat_en, cue_obj_en, S_en, 2747, 2);\n",
    "accs_de = monolingual_learning_comp(dat_de, cue_obj_de, S_de, 2747, 2);\n",
    "accs_zh = monolingual_learning_comp(dat_zh, cue_obj_zh, S_zh, 2747, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_en, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(accs_de, label=\"German\")\n",
    "plot!(accs_zh, label=\"Mandarin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_seq = JudiLing.make_learn_seq(dat_en.simFreq, random_seed=314);\n",
    "eval_size = 2747\n",
    "n_evals = Int64(length(learn_seq)/eval_size); # 6\n",
    "F = zeros(size(cue_obj_en.C)[2], size(S)[2])\n",
    "G = zeros(size(S)[2], size(cue_obj_en.C)[2])\n",
    "\n",
    "accs_prod = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_en.C, S_en, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    G = JudiLing.wh_learn(S_en, cue_obj_en.C, learn_seq=learn_seq_epoch, eta=0.01, weights=G)\n",
    "    Chat = S * G\n",
    "\n",
    "    #learn path\n",
    "    res = JudiLing.learn_paths(dat_en, cue_obj_en, S_en, F, Chat, threshold=0.01, verbose=false)\n",
    "    acc_p = JudiLing.eval_acc(res, cue_obj_en)\n",
    "    push!(accs_prod, acc_p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function monolingual_learning_prod(data, cue_obj, S, eval_size, whole_epoch_rep)\n",
    "\n",
    "    learn_seq = repeat(JudiLing.make_learn_seq(Int64.(data.simFreq), random_seed=314), whole_epoch_rep);\n",
    "    evals = collect(Int64, 1:(length(learn_seq)/eval_size))\n",
    "    F = zeros(size(cue_obj.C)[2], size(S)[2])\n",
    "    G = zeros(size(S)[2], size(cue_obj.C)[2])\n",
    "\n",
    "    accs_prod = []\n",
    "    for i in evals\n",
    "        learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "        F = JudiLing.wh_learn(cue_obj.C, S, learn_seq=learn_seq_epoch, eta=0.01, weights=F, n_epochs=1)\n",
    "        G = JudiLing.wh_learn(S, cue_obj.C, learn_seq=learn_seq_epoch, eta=0.01, weights=G, n_epochs=1)\n",
    "        Chat = S * G\n",
    "\n",
    "        #learn path\n",
    "        res = JudiLing.learn_paths(data, cue_obj, S, F, Chat, threshold=0.01, verbose=false)\n",
    "        acc_p = JudiLing.eval_acc(res, cue_obj)\n",
    "        push!(accs_prod, acc_p)\n",
    "    end\n",
    "    accs_prod\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_en = monolingual_learning_prod(dat_en, cue_obj_en, S_en, 2747, 1);\n",
    "prod_de = monolingual_learning_prod(dat_de, cue_obj_de, S_de, 2747, 1);\n",
    "prod_zh = monolingual_learning_prod(dat_zh, cue_obj_zh, S_zh, 2747, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(prod_en, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(prod_de, label=\"German\")\n",
    "plot!(prod_zh, label=\"Mandarin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilingual learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_bi = vcat(dat_en, dat_de);\n",
    "cue_obj_bi = JudiLing.make_cue_matrix(dat_bi, grams=3, target_col=:Phon);\n",
    "S_bi = vcat(S_en, S_de);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simultaneous bilingual: comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_seq_bi = JudiLing.make_learn_seq(dat_bi.simFreq, random_seed=314);\n",
    "eval_size = 2747\n",
    "n_evals = Int64(length(learn_seq_bi)/eval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_bi.C)[2], size(S_bi)[2])\n",
    "\n",
    "accs_L1 = [] # English\n",
    "accs_L2 = [] # German\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq_bi[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_bi.C, S_bi, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    Shat = cue_obj_bi.C * F\n",
    "    acc, R = JudiLing.eval_SC(Shat, S_bi, R=true)\n",
    "    accs = [R[j[1], j[1]] == R[j] ? 1 : 0 for j in argmax(R, dims = 2)]\n",
    "    # L1\n",
    "    acc_L1 = sum(accs[1:nrow(dat_en)])/nrow(dat_en)\n",
    "    push!(accs_L1, acc_L1)\n",
    "    # L2\n",
    "    acc_L2 = sum(accs[(nrow(dat_en)+1):nrow(dat_bi)])/nrow(dat_de)\n",
    "    push!(accs_L2, acc_L2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(accs_L2, label=\"German\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simultaneous bilingual: production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_bi.C)[2], size(S_bi)[2])\n",
    "G = zeros(size(S_bi)[2], size(cue_obj_bi.C)[2])\n",
    "\n",
    "accs_prod_bi = []\n",
    "forms_prod_bi = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq_bi[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_bi.C, S_bi, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    G = JudiLing.wh_learn(S_bi, cue_obj_bi.C, learn_seq=learn_seq_epoch, eta=0.01, weights=G)\n",
    "    Chat = S_bi * G\n",
    "\n",
    "    res = JudiLing.learn_paths(dat_bi, cue_obj_bi, S_bi, F, Chat, threshold=0.01, verbose=false)\n",
    "    # get by-word accuracy and predicted form\n",
    "     accs_prod = []\n",
    "     forms_prod = []\n",
    "     for k in 1:nrow(dat_bi)\n",
    "         acc_p = JudiLing.iscorrect(cue_obj_bi.gold_ind[k], res[k][1].ngrams_ind)\n",
    "         push!(accs_prod, acc_p)\n",
    "         form_p = JudiLing.translate(res[k][1].ngrams_ind, cue_obj_bi.i2f, 3, false, nothing, \"#\", \"\")\n",
    "         push!(forms_prod, form_p)\n",
    "     end\n",
    "     push!(accs_prod_bi, accs_prod)\n",
    "     push!(forms_prod_bi, forms_prod)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further processing of the production results\n",
    "accs_prod_L1 = []\n",
    "accs_prod_L2 = []\n",
    "intru_in_L1 = []\n",
    "intru_in_L2 = []\n",
    "\n",
    "for i in 1:length(forms_prod_bi)\n",
    "    accs_tmp = accs_prod_bi[i]\n",
    "    forms_tmp = forms_prod_bi[i]\n",
    "    # L1\n",
    "    acc_L1 = sum(accs_tmp[1:nrow(dat_en)])/nrow(dat_en)\n",
    "    push!(accs_prod_L1, acc_L1)\n",
    "\n",
    "    p_L1 = forms_tmp[1:nrow(dat_en)]\n",
    "    intru_L1 = []\n",
    "    for (j, x) in enumerate(p_L1)\n",
    "        if x == dat_en.Phon[j]\n",
    "            push!(intru_L1, false)\n",
    "        elseif x == dat_de.Phon[j]\n",
    "            push!(intru_L1, true)\n",
    "        else\n",
    "            push!(intru_L1, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L1, sum(intru_L1)/length(p_L1))\n",
    "    \n",
    "    # L2\n",
    "    acc_L2 = sum(accs_tmp[(nrow(dat_en)+1):nrow(dat_bi)])/nrow(dat_de)\n",
    "    push!(accs_prod_L2, acc_L2)\n",
    "\n",
    "    p_L2 = forms_tmp[(nrow(dat_en)+1):nrow(dat_bi)]\n",
    "    intru_L2 = []\n",
    "    for (j, x) in enumerate(p_L2)\n",
    "        if x == dat_de.Phon[j]\n",
    "            push!(intru_L2, false)\n",
    "        elseif x == dat_en.Phon[j]\n",
    "            push!(intru_L2, true)\n",
    "        else\n",
    "            push!(intru_L2, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L2, sum(intru_L2)/length(p_L2))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_prod_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\", legend=:right)\n",
    "plot!(accs_prod_L2, label=\"German\")\n",
    "plot!(intru_in_L1, label=\"G ii E\", ls=:dash, lc=1)\n",
    "plot!(intru_in_L2, label=\"E ii G\", ls=:dash, lc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Late bilingual: comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_size = 2747;\n",
    "L1_only_eval = 5;\n",
    "bi_eval = 7;\n",
    "n_rep = 2;\n",
    "learn_seq_p1 = repeat(JudiLing.make_learn_seq(dat_en.simFreq, random_seed=314), n_rep);\n",
    "learn_seq_p2 = repeat(JudiLing.make_learn_seq(dat_bi.simFreq, random_seed=314), n_rep);\n",
    "learn_seq_late = vcat(learn_seq_p1[1:eval_size*L1_only_eval], learn_seq_p2[1:eval_size*bi_eval])\n",
    "n_evals = Int64(length(learn_seq_late)/eval_size); # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_bi.C)[2], size(S_bi)[2])\n",
    "accs_L1 = [] # English\n",
    "accs_L2 = [] # German\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq_late[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_bi.C, S_bi, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    Shat = cue_obj_bi.C * F\n",
    "    acc, R = JudiLing.eval_SC(Shat, S_bi, R=true)\n",
    "    accs = [R[j[1], j[1]] == R[j] ? 1 : 0 for j in argmax(R, dims = 2)]\n",
    "    # L1\n",
    "    acc_L1 = sum(accs[1:nrow(dat_en)])/nrow(dat_en)\n",
    "    push!(accs_L1, acc_L1)\n",
    "    # L2\n",
    "    acc_L2 = sum(accs[(nrow(dat_en)+1):nrow(dat_bi)])/nrow(dat_de)\n",
    "    push!(accs_L2, acc_L2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(accs_L2, label=\"German\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Late bilingual: production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_bi.C)[2], size(S_bi)[2])\n",
    "G = zeros(size(S_bi)[2], size(cue_obj_bi.C)[2])\n",
    "\n",
    "accs_prod_bi = []\n",
    "forms_prod_bi = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq_late[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_bi.C, S_bi, learn_seq=learn_seq_epoch, eta=0.01, weights=F)\n",
    "    G = JudiLing.wh_learn(S_bi, cue_obj_bi.C, learn_seq=learn_seq_epoch, eta=0.01, weights=G)\n",
    "    Chat = S_bi * G\n",
    "\n",
    "    res = JudiLing.learn_paths(dat_bi, cue_obj_bi, S_bi, F, Chat, threshold=0.01, verbose=false)\n",
    "    # get by-word accuracy and predicted form\n",
    "     accs_prod = []\n",
    "     forms_prod = []\n",
    "     for k in 1:nrow(dat_bi)\n",
    "        if isassigned(res[k], 1)\n",
    "            acc_p = JudiLing.iscorrect(cue_obj_bi.gold_ind[k], res[k][1].ngrams_ind)\n",
    "            push!(accs_prod, acc_p)\n",
    "            form_p = JudiLing.translate(res[k][1].ngrams_ind, cue_obj_bi.i2f, 3, false, nothing, \"#\", \"\")\n",
    "            push!(forms_prod, form_p)\n",
    "         else\n",
    "            push!(accs_prod, false)\n",
    "            push!(forms_prod, \"NA\")\n",
    "         end\n",
    "     end\n",
    "     push!(accs_prod_bi, accs_prod)\n",
    "     push!(forms_prod_bi, forms_prod)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further processing of the production results\n",
    "accs_prod_L1 = []\n",
    "accs_prod_L2 = []\n",
    "intru_in_L1 = []\n",
    "intru_in_L2 = []\n",
    "\n",
    "for i in 1:length(forms_prod_bi)\n",
    "    accs_tmp = accs_prod_bi[i]\n",
    "    forms_tmp = forms_prod_bi[i]\n",
    "    # L1\n",
    "    acc_L1 = sum(accs_tmp[1:nrow(dat_en)])/nrow(dat_en)\n",
    "    push!(accs_prod_L1, acc_L1)\n",
    "\n",
    "    p_L1 = forms_tmp[1:nrow(dat_en)]\n",
    "    intru_L1 = []\n",
    "    for (j, x) in enumerate(p_L1)\n",
    "        if x == dat_en.Phon[j]\n",
    "            push!(intru_L1, false)\n",
    "        elseif x == dat_de.Phon[j]\n",
    "            push!(intru_L1, true)\n",
    "        else\n",
    "            push!(intru_L1, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L1, sum(intru_L1)/length(p_L1))\n",
    "    \n",
    "    # L2\n",
    "    acc_L2 = sum(accs_tmp[(nrow(dat_en)+1):nrow(dat_bi)])/nrow(dat_de)\n",
    "    push!(accs_prod_L2, acc_L2)\n",
    "\n",
    "    p_L2 = forms_tmp[(nrow(dat_en)+1):nrow(dat_bi)]\n",
    "    intru_L2 = []\n",
    "    for (j, x) in enumerate(p_L2)\n",
    "        if x == dat_de.Phon[j]\n",
    "            push!(intru_L2, false)\n",
    "        elseif x == dat_en.Phon[j]\n",
    "            push!(intru_L2, true)\n",
    "        else\n",
    "            push!(intru_L2, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L2, sum(intru_L2)/length(p_L2))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_prod_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\", legend=:right)\n",
    "plot!(accs_prod_L2, label=\"German\")\n",
    "plot!(intru_in_L1, label=\"G ii E\", ls=:dash, lc=1)\n",
    "plot!(intru_in_L2, label=\"E ii G\", ls=:dash, lc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trilingual learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_size = 2747;\n",
    "L1_only_eval = 5;\n",
    "bi_eval = 7;\n",
    "tri_eval = 8;\n",
    "n_rep = 2;\n",
    "data_L1 = dat_en;\n",
    "data_L2 = dat_de;\n",
    "data_L3 = dat_zh;\n",
    "S_L1 = S_en;\n",
    "S_L2 = S_de;\n",
    "S_L3 = S_zh;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_bi = vcat(data_L1, data_L2);\n",
    "dat_tri = vcat(data_L1, data_L2, data_L3);\n",
    "cue_obj_tri = JudiLing.make_cue_matrix(dat_tri, grams=3, target_col=:Phon);\n",
    "S_tri = vcat(S_en, S_de, S_zh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_seq_p1 = repeat(JudiLing.make_learn_seq(data_L1.simFreq, random_seed=314), n_rep);\n",
    "learn_seq_p2 = repeat(JudiLing.make_learn_seq(dat_bi.simFreq, random_seed=314), n_rep);\n",
    "learn_seq_p3 = repeat(JudiLing.make_learn_seq(dat_tri.simFreq, random_seed=314), n_rep);\n",
    "learn_seq = vcat(learn_seq_p1[1:eval_size*L1_only_eval], learn_seq_p2[1:eval_size*bi_eval], learn_seq_p3[1:eval_size*tri_eval])\n",
    "n_evals = Int64(length(learn_seq)/eval_size) #20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_tri.C)[2], size(S_tri)[2])\n",
    "\n",
    "accs_L1 = []\n",
    "accs_L2 = []\n",
    "accs_L3 = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_tri.C, S_tri, learn_seq=learn_seq_epoch, eta=0.01, weights=F, n_epochs=1)\n",
    "    Shat = cue_obj_tri.C * F\n",
    "    # strict evaluation\n",
    "    acc, R = JudiLing.eval_SC(Shat, S_tri, R=true)\n",
    "    accs = [R[j[1], j[1]] == R[j] ? 1 : 0 for j in argmax(R, dims = 2)]\n",
    "\n",
    "    # L1\n",
    "    acc_L1 = sum(accs[1:nrow(data_L1)])/nrow(data_L1)\n",
    "    push!(accs_L1, acc_L1)\n",
    "    # L2\n",
    "    acc_L2 = sum(accs[(nrow(data_L1)+1):nrow(dat_bi)])/nrow(data_L2)\n",
    "    push!(accs_L2, acc_L2)\n",
    "    # L3\n",
    "    acc_L3 = sum(accs[(nrow(dat_bi)+1):nrow(dat_tri)])/nrow(data_L3)\n",
    "    push!(accs_L3, acc_L3)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\")\n",
    "plot!(accs_L2, label=\"German\")\n",
    "plot!(accs_L3, label=\"Mandarin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = zeros(size(cue_obj_tri.C)[2], size(S_tri)[2])\n",
    "G = zeros(size(S_tri)[2], size(cue_obj_tri.C)[2])\n",
    "\n",
    "accs_prod_tri = []\n",
    "forms_prod_tri = []\n",
    "for i in 1:n_evals\n",
    "    learn_seq_epoch = learn_seq[(((i-1)*eval_size)+1):i*eval_size]\n",
    "    F = JudiLing.wh_learn(cue_obj_tri.C, S_tri, learn_seq=learn_seq_epoch, eta=0.01, weights=F, n_epochs=1)\n",
    "    G = JudiLing.wh_learn(S_tri, cue_obj_tri.C, learn_seq=learn_seq_epoch, eta=0.01, weights=G, n_epochs=1)\n",
    "    Shat = cue_obj_tri.C * F\n",
    "    Chat = S_tri * G\n",
    "\n",
    "    # learn path\n",
    "    res = JudiLing.learn_paths(dat_tri, cue_obj_tri, S_tri, F, Chat, threshold=0.01, verbose=false);\n",
    "    # get by-word acc and predicted form\n",
    "     accs_prod = []\n",
    "     forms_prod = []\n",
    "     for k in 1:nrow(dat_tri)\n",
    "         if isassigned(res[k], 1)\n",
    "            acc_p = JudiLing.iscorrect(cue_obj_tri.gold_ind[k], res[k][1].ngrams_ind)\n",
    "            push!(accs_prod, acc_p)\n",
    "            form_p = JudiLing.translate(res[k][1].ngrams_ind, cue_obj_tri.i2f, 3, false, nothing, \"#\", \"\")\n",
    "            push!(forms_prod, form_p)\n",
    "         else\n",
    "            push!(accs_prod, false)\n",
    "            push!(forms_prod, \"NA\")\n",
    "         end\n",
    "     end\n",
    "     push!(accs_prod_tri, accs_prod)\n",
    "     push!(forms_prod_tri, forms_prod)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_prod_L1 = []\n",
    "accs_prod_L2 = []\n",
    "accs_prod_L3 = []\n",
    "intru_in_L1 = []\n",
    "intru_in_L2 = []\n",
    "intru_in_L3 = []\n",
    "\n",
    "for i in 1:length(forms_prod_tri)\n",
    "    accs_tmp = accs_prod_tri[i]\n",
    "    forms_tmp = forms_prod_tri[i]\n",
    "    # L1\n",
    "    acc_L1 = sum(accs_tmp[1:nrow(data_L1)])/nrow(data_L1)\n",
    "    push!(accs_prod_L1, acc_L1)\n",
    "\n",
    "    p_L1 = forms_tmp[1:nrow(data_L1)]\n",
    "    intru_L1 = []\n",
    "    for (j, x) in enumerate(p_L1)\n",
    "        if x == data_L1.Phon[j]\n",
    "            push!(intru_L1, false)\n",
    "        elseif x == data_L2.Phon[j] || x == data_L3.Phon[j]\n",
    "            push!(intru_L1, true)\n",
    "        else\n",
    "            push!(intru_L1, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L1, sum(intru_L1)/length(p_L1))\n",
    "    \n",
    "    # L2\n",
    "    acc_L2 = sum(accs_tmp[(nrow(data_L1)+1):nrow(dat_bi)])/nrow(data_L2)\n",
    "    push!(accs_prod_L2, acc_L2)\n",
    "\n",
    "    p_L2 = forms_tmp[(nrow(data_L1)+1):nrow(dat_bi)]\n",
    "    intru_L2 = []\n",
    "    for (j, x) in enumerate(p_L2)\n",
    "        if x == data_L2.Phon[j]\n",
    "            push!(intru_L2, false)\n",
    "        elseif x == data_L1.Phon[j] || x == data_L3.Phon[j]\n",
    "            push!(intru_L2, true)\n",
    "        else\n",
    "            push!(intru_L2, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L2, sum(intru_L2)/length(p_L2))\n",
    "\n",
    "    # L3\n",
    "    acc_L3 = sum(accs_tmp[(nrow(dat_bi)+1):nrow(dat_tri)])/nrow(data_L3)\n",
    "    push!(accs_prod_L3, acc_L3)\n",
    "\n",
    "    p_L3 = forms_tmp[(nrow(dat_bi)+1):nrow(dat_tri)]\n",
    "    intru_L3 = []\n",
    "    for (j, x) in enumerate(p_L3)\n",
    "        if x == data_L3.Phon[j]\n",
    "            push!(intru_L3, false)\n",
    "        elseif x == data_L1.Phon[j] || x == data_L2.Phon[j]\n",
    "            push!(intru_L3, true)\n",
    "        else\n",
    "            push!(intru_L3, false)\n",
    "        end\n",
    "    end\n",
    "    push!(intru_in_L3, sum(intru_L3)/length(p_L3))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(accs_prod_L1, xlab=\"evaluation step\", ylab=\"accuracy\", label=\"English\", legend=:left)\n",
    "plot!(accs_prod_L2, label=\"German\")\n",
    "plot!(accs_prod_L3, label=\"Mandarin\")\n",
    "plot!(intru_in_L1, label=\"G/M ii E\", ls=:dash, lc=1)\n",
    "plot!(intru_in_L2, label=\"E/M ii G\", ls=:dash, lc=2)\n",
    "plot!(intru_in_L3, label=\"E/G ii M\", ls=:dash, lc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
