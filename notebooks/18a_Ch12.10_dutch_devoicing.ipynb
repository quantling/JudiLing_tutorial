{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7a8d16",
   "metadata": {},
   "source": [
    "# Chapter 12.10: Dutch devoicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86717249",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "Load the necessary packages. In addition to the usual packages, for this part we also require two additional packages: `StatsBase` which includes basic functions for use in statistics. You can find more information about this package [here](https://juliastats.org/StatsBase.jl/stable/). Secondly, we require `Random`, a julia base package which includes functionality for random number generation, more information [here](https://docs.julialang.org/en/v1/stdlib/Random/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aeb815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"StatsBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42603c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JudiLing, DataFrames\n",
    "using StatsBase, Random, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee82d2",
   "metadata": {},
   "source": [
    "Load the usual dutch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69541c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the filepath to the location of your dutch.csv file.\n",
    "dutch = JudiLing.load_dataset(\"../dat/dutch.csv\");\n",
    "first(dutch, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b5fe1",
   "metadata": {},
   "source": [
    "## Performance on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174761c",
   "metadata": {},
   "source": [
    "Create a cue object. We are interested in the pronunciation of the wordforms and therefore use the `\"Word\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_obj = JudiLing.make_cue_matrix(dutch, grams=3, target_col=\"Word\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5b967",
   "metadata": {},
   "source": [
    "We also load the word2vec semantic vectors we have been using throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d070973",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, words = JudiLing.load_S_matrix(\"../dat/dutch_w2v.csv\"; header = false, sep = \",\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8426c",
   "metadata": {},
   "source": [
    "Make sure that the words in the semantic matrix and in the dutch dataset are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91829c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(words == dutch.Ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f0482",
   "metadata": {},
   "source": [
    "Train comprehension matrix and predict semantic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c23120",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = JudiLing.make_transform_matrix(cue_obj.C, S);\n",
    "Shat = cue_obj.C * F;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b676a",
   "metadata": {},
   "source": [
    "Compute comprehension accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d194bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_acc = JudiLing.eval_SC(Shat, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a99c5",
   "metadata": {},
   "source": [
    "Train production matrix and predict cue matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d224ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = JudiLing.make_transform_matrix(S, cue_obj.C);\n",
    "Chat = S * G;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf506a1",
   "metadata": {},
   "source": [
    "Compute produced forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e8e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_res = JudiLing.learn_paths(dutch, cue_obj, S, F, Chat,threshold=0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6465db",
   "metadata": {},
   "source": [
    "Get production accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d0477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_acc = JudiLing.eval_acc(prod_res, cue_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "JudiLing.write2csv(prod_res, dutch, cue_obj, cue_obj, \"../res/prod.csv\",\n",
    "target_col=:Word);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e59d7",
   "metadata": {},
   "source": [
    "Using frequency-informed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd52046",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_fil = JudiLing.make_transform_matrix(cue_obj.C, S, dutch.Frequency);\n",
    "Shat_fil = cue_obj.C * F_fil;\n",
    "\n",
    "c_acc_fil = JudiLing.eval_SC(Shat_fil, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e3a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_fil = JudiLing.make_transform_matrix(S, cue_obj.C, dutch.Frequency);\n",
    "Chat_fil = S * G_fil;\n",
    "\n",
    "prod_res_fil = JudiLing.learn_paths(dutch, cue_obj, S, F_fil, Chat_fil,threshold=0.01);\n",
    "\n",
    "p_acc_fil = JudiLing.eval_acc(prod_res_fil, cue_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a28f1a",
   "metadata": {},
   "source": [
    "## Performance on held-out plural forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c7464",
   "metadata": {},
   "source": [
    "First, we need to create a split where the test data only contains plural forms. Unfortunately, this is a task beyond the capabilities of the `loading_data_careful_split` function in JudiLing, so we need to make the split manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7351041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(dutch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85c4e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a list of the rownumbers in the full dutch dataset\n",
    "rownumbers = 1:nrow(dutch)\n",
    "# of these, select only those which correspond to plural forms\n",
    "plural_rownumbers = rownumbers[dutch.Number .== \"plural\"]\n",
    "# filter plural rownumbers to only include those where the singular is available in the data\n",
    "plural_rownumbers = [ro for ro in plural_rownumbers \n",
    "        if dutch[ro, :Lexeme] in dutch[dutch.Number .== \"singular\", :Lexeme]]\n",
    "# sample 100 plural rows. To make this reproducible, first set a random seed.\n",
    "Random.seed!(3)\n",
    "test_rows = sample(plural_rownumbers,100, replace=false)\n",
    "# the remaining row numbers should go into the training set\n",
    "train_rows = setdiff(rownumbers, test_rows)\n",
    "\n",
    "# create final training and test sets\n",
    "dutch_train = dutch[train_rows,:]\n",
    "dutch_test = dutch[test_rows,:]\n",
    "dutch_train_test = vcat(dutch_train, dutch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e21ac",
   "metadata": {},
   "source": [
    "Create cue objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one cue object for the training and test data combined (will be needed below)\n",
    "cue_obj_train_test = JudiLing.make_cue_matrix(dutch_train_test, grams=3, target_col=\"Word\");\n",
    "\n",
    "# create cue objects for the training and test data respectively\n",
    "cue_obj_train, cue_obj_test = JudiLing.make_combined_cue_matrix(dutch_train, dutch_test, grams=3, target_col=\"Word\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a03696",
   "metadata": {},
   "source": [
    "Split the S matrix into test, train and a combined S matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test = S[test_rows,:]\n",
    "S_train = S[train_rows,:]\n",
    "\n",
    "# we need to create this combined S matrix to make sure that the rows here are \n",
    "# in the same order as in dutch_train_test and cue_obj_train_test\n",
    "S_train_test = vcat(S_train, S_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf97a4",
   "metadata": {},
   "source": [
    "Create one F matrix based on the train AND test data, and one based only on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_train_test = JudiLing.make_transform_matrix(cue_obj_train_test.C, S_train_test);\n",
    "F_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4064d-ed83-47c3-8cf2-d1e57384b0cb",
   "metadata": {},
   "source": [
    "Inspect the accuracy of the F matrix trained only on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f533f71-da1f-410c-b784-7e40b7232b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shat_train = cue_obj_train.C * F_train\n",
    "@show JudiLing.eval_SC(Shat_train, S_train, dutch_train, \"Word\")\n",
    "Shat_test = cue_obj_test.C * F_train\n",
    "@show JudiLing.eval_SC(Shat_test, S_test, S_train, dutch_test, dutch_train, \"Word\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6c001",
   "metadata": {},
   "source": [
    "Create a G matrix based on the training data and predict the form matrix for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b48589",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C);\n",
    "Chat_train = S_train * G_train;\n",
    "Chat_test = S_test * G_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471df712",
   "metadata": {},
   "source": [
    "Calculate maximum number of production steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = JudiLing.cal_max_timestep(dutch_train, dutch_test, \"Word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae4051",
   "metadata": {},
   "source": [
    "Produce forms based on the F matrix trained on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test = JudiLing.learn_paths(dutch_train,\n",
    "                                 dutch_test, \n",
    "                                 cue_obj_train.C, \n",
    "                                 S_test,\n",
    "                                 F_train_test, # set F matrix trained on train and test data here\n",
    "                                 Chat_test, \n",
    "                                 cue_obj_test.A, \n",
    "                                 cue_obj_train.i2f, \n",
    "                                 cue_obj_train.f2i,\n",
    "                                 max_t=14, \n",
    "                                 threshold=0.001, \n",
    "                                 grams=3,\n",
    "                                 is_tolerant = true, \n",
    "                                 tolerance = -0.1, \n",
    "                                 max_tolerance = 2, \n",
    "                                 target_col=\"Word\");\n",
    "JudiLing.eval_acc(prod_test, cue_obj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183cf90",
   "metadata": {},
   "source": [
    "Produce forms based on the F matrix trained on the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test2 = JudiLing.learn_paths(dutch_train,\n",
    "                                  dutch_test, \n",
    "                                  cue_obj_train.C, \n",
    "                                  S_test,\n",
    "                                  F_train, # set F matrix trained on train data only here\n",
    "                                  Chat_test, \n",
    "                                  cue_obj_test.A, \n",
    "                                  cue_obj_train.i2f, \n",
    "                                  cue_obj_train.f2i,\n",
    "                                  max_t=14, \n",
    "                                  threshold=0.001, \n",
    "                                  grams=3,\n",
    "                                  is_tolerant = true, \n",
    "                                  tolerance = -0.1, \n",
    "                                  max_tolerance = 2, \n",
    "                                  target_col=\"Word\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c7d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JudiLing.eval_acc(prod_test2, cue_obj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95223d22",
   "metadata": {},
   "source": [
    "Accuracy among top 10 candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce7879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JudiLing.eval_acc_loose(prod_test2, cue_obj_test.gold_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb657b",
   "metadata": {},
   "source": [
    "## Inspecting shift vectors\n",
    "\n",
    "This part of the code does not require any knowledge of JudiLing. For completeness' sake, we provide it in the following anyway.\n",
    "\n",
    "First, we turn the dutch dataset into a wide dataset where each row provides the singular and plural form for each lexeme. We get rid of rows where the singular or plural form is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f644471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dutch_wide = unstack(dutch, [:Lexeme, :WordCat, :Voice], :Number, :Ortho, allowduplicates=true)\n",
    "dutch_wide = dropmissing(dutch_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7df054",
   "metadata": {},
   "source": [
    "Next, we split up the S matrix, such that we have one matrix with the semantic vectors of all singulars, and one with all plurals. Moreover, we make sure that in both matrices the vectors are ordered according to `dutch_wide`. Practically, this means that in the first row of `S_singular` will be the semantic vector of the singular form of the word whose plural form's semantic vector is in the first row of `S_plural`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "singular_rownumbers = [findall(x->x==w, dutch.Ortho)[1] for w in dutch_wide.singular]\n",
    "plural_rownumbers = [findall(x->x==w, dutch.Ortho)[1] for w in dutch_wide.plural]\n",
    "\n",
    "S_singular = S[singular_rownumbers,:]\n",
    "S_plural = S[plural_rownumbers,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25696740",
   "metadata": {},
   "source": [
    "Now, we can calculate the correlation between each pair of singular and plural semantic vector, and get the range as well as the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66266c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cors = diag(cor(S_singular, S_plural, dims = 2))\n",
    "print(findmin(cors), findmax(cors), median(cors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae9ef7",
   "metadata": {},
   "source": [
    "The shift vectors are calculated by subtracting the singular vectors from the plural vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d691c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shift_vectors = S_plural .- S_singular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fa304",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812f6b4",
   "metadata": {},
   "source": [
    "Next, we require the `TSne` and `Plots` libraries. If you have not done so before, you can install them with the following piece of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bf669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"TSne\")\n",
    "Pkg.add(\"Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e983fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TSne, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d28e9",
   "metadata": {},
   "source": [
    "We now run TSne on the shift vectors we have calculated above (note that a warning will show up, this can be savely ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3)\n",
    "Y = tsne(shift_vectors, 2, 50, 1000, 30.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0309b3",
   "metadata": {},
   "source": [
    "...and we can plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "markercolors = [colorant\"#FE8892\",\n",
    "                  colorant\"#8FAADC\",\n",
    "                  colorant\"#FE8892\",\n",
    "                  colorant\"#8FAADC\"]\n",
    "labels = [\"Noun non-alt.\", \"Verb non-alt.\", \"Noun alternating\", \"Verb alternating\"]\n",
    "markershapes = [:star4, :star4, :circle, :circle]\n",
    "dutch_wide[!,\"voice_wordcat\"] = string.(dutch_wide.Voice, \"_\", dutch_wide.WordCat)\n",
    "p = scatter(xlab=\"tSNE dimension 1\", ylab=\"tSNE dimension 2\")\n",
    "for (i, comb) in enumerate([\"voiceless_noun\", \"voiceless_verb\", \"voiced_noun\", \"voiced_verb\",])\n",
    "    scatter!(Y[dutch_wide.voice_wordcat .== comb,1], Y[dutch_wide.voice_wordcat .== comb,2], \n",
    "            markershape = markershapes[i],\n",
    "            markercolor = markercolors[i],\n",
    "        markersize=3.5,\n",
    "        markerstrokewidth=0.3,\n",
    "    label = labels[i])\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac07cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savefig(\"../fig/tsne_shift_vectors.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6984688",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8149a0",
   "metadata": {},
   "source": [
    "As there is so far no good library for performing LDA for classification in julia, we now move to R. Luckily, we can do this directly from julia, by making use of the `RCall` library which can be installed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd1836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"RCall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8561a0",
   "metadata": {},
   "source": [
    "Here, we put the shift vectors as well as the dutch wide dataset into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e927338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@rput shift_vectors\n",
    "@rput dutch_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab4632",
   "metadata": {},
   "source": [
    "We load the MASS library in R (after installing it, if necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24106a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "# install.packages(\"MASS\")\n",
    "\n",
    "library(MASS)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346f7e4",
   "metadata": {},
   "source": [
    "Now we run the LDA on the shift vectors and extract the prior probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f7537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "ld = lda(x = shift_vectors, grouping = dutch_wide$Voice)\n",
    "ld$prior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30d585",
   "metadata": {},
   "source": [
    "And predict and evaluate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26190d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "pred = predict(ld, shift_vectors)$class\n",
    "\n",
    "mean(pred == dutch_wide$Voice)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98317e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "\n",
    "table(dutch_wide$Voice)/length(dutch_wide$Voice)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e795765-e6a3-4614-bc8f-9719d847642e",
   "metadata": {},
   "source": [
    "Run Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ded66-9e83-4c2b-be33-ad833f7e9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "ldCV = lda(x = shift_vectors, grouping = dutch_wide$Voice, CV=T)\n",
    "pred = ldCV$class\n",
    "\n",
    "mean(pred == dutch_wide$Voice)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af80749-e1be-45be-89b2-61b01bc1019e",
   "metadata": {},
   "source": [
    "Cross-validation does not outperform the majority baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dd6fd",
   "metadata": {},
   "source": [
    "### Frequency analysis of singular and plurals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c0877",
   "metadata": {},
   "source": [
    "Number of wordforms per number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = groupby(dutch, :Number)\n",
    "combine(gdf, nrow; renamecols=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f124a9",
   "metadata": {},
   "source": [
    "Frequency per number + wordcat combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e671f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dutch[!,\"LogFrequency\"] = log.(dutch.Frequency.+ 0.002);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4fdc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = groupby(dutch, [:WordCat, :Number])\n",
    "combine(gdf, :LogFrequency => mean; renamecols=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6efd4-ecad-48cf-bfd5-bea4c13b4e28",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9438b-8779-48b7-9f16-45b053dd7be6",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Comparing production accuracy for EL and FIL. EL was done above already, so here we just have to do FIL. Let's use the version where the comprehension matrix is trained on both the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722abb89-628b-4039-8da9-744fa9e7a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_fil_train_test = JudiLing.make_transform_matrix(cue_obj_train_test.C, S_train_test, dutch_train_test.Frequency);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c3afb-340f-4521-8429-b199ad464643",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_fil_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C, dutch_train.Frequency);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a24d9-b715-4b2f-b4d7-33be0148b4b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chat_fil_test = S_test * G_fil_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9cf86-498f-4acb-aeb6-c19dfd0610c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_fil_test = JudiLing.learn_paths(dutch_train,\n",
    "                                 dutch_test, \n",
    "                                 cue_obj_train.C, \n",
    "                                 S_test,\n",
    "                                 F_fil_train_test, # set F matrix trained on train and test data here\n",
    "                                 Chat_fil_test, \n",
    "                                 cue_obj_test.A, \n",
    "                                 cue_obj_train.i2f, \n",
    "                                 cue_obj_train.f2i,\n",
    "                                 max_t=14, \n",
    "                                 threshold=0.001, \n",
    "                                 grams=3,\n",
    "                                 is_tolerant = true, \n",
    "                                 tolerance = -0.1, \n",
    "                                 max_tolerance = 2, \n",
    "                                 target_col=\"Word\");\n",
    "JudiLing.eval_acc(prod_fil_test, cue_obj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3165a-5567-439d-84ef-a68b287c3bb8",
   "metadata": {},
   "source": [
    "27% is clearly worse than the 88% we got above with EL.\n",
    "\n",
    "Compute accuracies for alternating vs non-alternating plurals and singulars.\n",
    "\n",
    "First for EL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92431e05-e966-482e-b43f-0be7bdd1392a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the production results to a dataframe\n",
    "df = JudiLing.write2df(prod_test, dutch_test, cue_obj_train, cue_obj_test, target_col=\"Word\")\n",
    "# only keep the top candidate for each target word\n",
    "top_cands = df[(df.isbest .== true) .| (ismissing.(df.isbest)),:]\n",
    "# merge the dutch dataset back in\n",
    "top_cands = hcat(top_cands, dutch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9028b-d618-4854-8881-ea2b999b7b01",
   "metadata": {},
   "source": [
    "Compute accuracy for alternating and non-alternating words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed345d-83b8-4b16-86a4-410e75cf77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(top_cands, [:Voice]), :iscorrect => mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d08e67-3598-4e32-8f62-75b5684b22fd",
   "metadata": {},
   "source": [
    "And for FIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d5780-b02d-4502-9a30-11e25648e990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the production results to a dataframe\n",
    "df_fil = JudiLing.write2df(prod_fil_test, dutch_test, cue_obj_train, cue_obj_test, target_col=\"Word\")\n",
    "# only keep the top candidate for each target word\n",
    "top_cands_fil = df_fil[(df_fil.isbest .== true) .| (ismissing.(df_fil.isbest)),:]\n",
    "# merge the dutch dataset back in\n",
    "top_cands_fil = hcat(top_cands_fil, dutch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e81ff-e018-4c05-8385-091f759ca4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine(groupby(top_cands_fil, [:Voice]), :iscorrect => mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7dd692-cbfd-430b-a1a0-6ab045f6b0d9",
   "metadata": {},
   "source": [
    "For both EL and FIL the accuracy is somewhat lower for alternating compared to non-alternating words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6e841-fb2b-4730-94c1-3b572b6dce3a",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bde7f-fd96-4992-8e48-90fd7b85ec37",
   "metadata": {},
   "source": [
    "This is easiest by copying the present notebook and rerunning the analysis using fasttext. See the next notebook for solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
